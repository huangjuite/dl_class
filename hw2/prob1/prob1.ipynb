{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sn\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pygal\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import Image\n",
    "from tqdm import trange, tqdm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as trns\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"GRU\" # \"LSTM\" or \"GRU\"\n",
    "correlation_thres = 0.8\n",
    "batch_size = 128\n",
    "sequence_len=7\n",
    "train_test_r = 0.7\n",
    "learning_rate = 0.001\n",
    "epoch = 600\n",
    "evaluate_thres=0.5\n",
    "visual_folder = \"./visual_%s\"%method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"covid_19.csv\").drop([0,1])\n",
    "infection_data = raw_data.drop(['Lat','Long'],axis=1)\n",
    "country_names = raw_data.iloc[:,0]\n",
    "position_data = raw_data.iloc[:,1:3].to_numpy().astype(np.float32)\n",
    "infection_data = infection_data.iloc[:,1:].to_numpy().astype(np.float32)\n",
    "\n",
    "infection_data = np.diff(infection_data,axis=1)\n",
    "print(\"%d countries in data\"%infection_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "core_mat = np.corrcoef(infection_data).astype(np.float32)\n",
    "np.fill_diagonal(core_mat, 0)\n",
    "core_max = np.max(core_mat,axis=1)\n",
    "plt.title(\"maximum correlation coefficient with other countries\")\n",
    "plt.plot(core_max)\n",
    "plt.savefig(visual_folder+'/correlation_coefficient.png', bbox_inches = \"tight\")\n",
    "# plt.show()\n",
    "core_mat = np.tril(core_mat)\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.title(\"infections data correlation coefficient between 185 countries\")\n",
    "sn.heatmap(core_mat)\n",
    "plt.savefig(visual_folder+'/correlation_matrix.png', bbox_inches = \"tight\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "infection_inlier_data = infection_data[np.where(core_max>=correlation_thres)]\n",
    "print(\"remove maximum correlation coefficient under %.3f\"% correlation_thres)\n",
    "\n",
    "print(\"%d countries left\"%infection_inlier_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_sequence(data,sequence_len=14):\n",
    "    sequence_data = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for k in range(data.shape[1]-sequence_len):\n",
    "            inputs = data[i][k:k+sequence_len]\n",
    "            inputs = np.expand_dims(inputs,axis=1)\n",
    "            label = torch.Tensor([1.0] if data[i][k+sequence_len-1] > data[i][k+sequence_len] else [0.0])\n",
    "            sequence_data.append({'inputs':inputs,'label':label})\n",
    "    return sequence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data = cut_sequence(infection_inlier_data,sequence_len)\n",
    "\n",
    "class infectionDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.transform = trns.Compose([trns.ToTensor()])\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        inputs = self.data[index]['inputs']\n",
    "        label = self.data[index]['label']\n",
    "        \n",
    "        return inputs, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = infectionDataset(sequence_data)\n",
    "train_sz = int(len(dataset)*train_test_r)\n",
    "test_sz = len(dataset)-train_sz\n",
    "train_set, test_set = random_split(dataset,[train_sz,test_sz])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # input gate\n",
    "        self.W_ui = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # forget gate\n",
    "        self.W_uf = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # internal_gate\n",
    "        self.W_ug = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hg = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_g = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # output gate\n",
    "        self.W_uo = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_ho = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
    "         \n",
    "        self.init_weights()\n",
    "     \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_size, feature_size = x.size()\n",
    "        h_t, c_t = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
    "        \n",
    "        # iterate over the time steps\n",
    "        for t in range(seq_size):\n",
    "            # shape (batch, sequence, feature)\n",
    "            x_t = x[:, t, :]\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ui + h_t @ self.W_hi + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.W_uf + h_t @ self.W_hf + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.W_ug + h_t @ self.W_hg + self.b_g)\n",
    "            o_t = torch.sigmoid(x_t @ self.W_uo + h_t @ self.W_ho + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "        \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUmodule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # update gate\n",
    "        self.W_iu = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hu = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_u = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # reset gate\n",
    "        self.W_ir = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hr = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_r = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # output gate\n",
    "        self.W_io = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_ho = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        \n",
    "         \n",
    "        self.init_weights()\n",
    "     \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_size, feature_size = x.size()\n",
    "        h_t = torch.zeros(self.hidden_size).to(x.device)\n",
    "        \n",
    "        # iterate over the time steps\n",
    "        for t in range(seq_size):\n",
    "            # shape (batch, sequence, feature)\n",
    "            x_t = x[:, t, :]\n",
    "            u_t = torch.sigmoid(x_t @ self.W_iu + h_t @ self.W_hu + self.b_u)\n",
    "            r_t = torch.sigmoid(x_t @ self.W_ir + h_t @ self.W_hr + self.b_r)\n",
    "            \n",
    "            o_t = torch.tanh(x_t @ self.W_io + ( r_t * h_t ) @ self.W_ho + self.b_o)\n",
    "            \n",
    "            h_t = (1-u_t) * h_t + u_t * o_t\n",
    "        \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataloader):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    total = len(dataloader.dataset)\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_hat = outputs.cpu().detach().numpy()\n",
    "        y_hat = np.where(y_hat>evaluate_thres,1,0)\n",
    "        y = labels.cpu().detach().numpy()\n",
    "        error += np.count_nonzero(y-y_hat)\n",
    "    model.train()\n",
    "    return (1-(error/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1\n",
    "input_size = 1\n",
    "\n",
    "if method == \"LSTM\":\n",
    "    module = LSTMmodule(input_size, hidden_size)\n",
    "elif method==\"GRU\":\n",
    "    module = GRUmodule(input_size, hidden_size)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "module.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(module.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "train_acc.append(evaluate(module,train_loader))\n",
    "test_acc.append(evaluate(module,test_loader))\n",
    "\n",
    "t = trange(epoch)\n",
    "for e in t:\n",
    "    loss_log = []\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = module.forward(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_log.append(loss.item())\n",
    "    train_acc.append(evaluate(module,train_loader))\n",
    "    test_acc.append(evaluate(module,test_loader))\n",
    "    losses.append(np.mean(loss_log))\n",
    "    t.set_description(\"train_loss:%.4f, train_acc:%.4f, test_acc:%.4f\"%(losses[-1],train_acc[-1],test_acc[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"train loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"average loss\")\n",
    "plt.plot(losses)\n",
    "plt.savefig(visual_folder+'/train_loss.png', bbox_inches = \"tight\")\n",
    "# plt.show()\n",
    "\n",
    "plt.title(\"train accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(train_acc)\n",
    "plt.savefig(visual_folder+'/train_accuracy.png', bbox_inches = \"tight\")\n",
    "# plt.show()\n",
    "\n",
    "plt.title(\"test accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(test_acc)\n",
    "plt.savefig(visual_folder+'/test_accuracy.png', bbox_inches = \"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES = {v: k for k, v in pygal.maps.world.COUNTRIES.items()}\n",
    "M_COUNTRIES = {\"Bolivia\":\"bo\", \n",
    "               \"Brunei\":\"bn\", \n",
    "               \"Congo (Brazzaville)\":\"cg\", \n",
    "               \"Congo (Kinshasa)\":\"cd\", \n",
    "               \"Czechia\":\"cz\", \n",
    "               \"Dominica\":\"do\",\n",
    "               \"Eswatini\":\"sz\",\n",
    "               \"Holy See\":\"va\",\n",
    "               \"Iran\":\"ir\",\n",
    "               \"Korea, South\":\"kr\",\n",
    "               \"Laos\":\"la\",\n",
    "               \"Libya\":\"ly\",\n",
    "               \"Moldova\":\"md\",\n",
    "               \"North Macedonia\":\"mk\",\n",
    "               \"Russia\":\"ru\",\n",
    "               \"Syria\":\"sy\",\n",
    "               \"Taiwan*\":\"tw\",\n",
    "               \"Tanzania\":\"tz\",\n",
    "               \"US\":\"us\",\n",
    "               \"Venezuela\":\"ve\",\n",
    "               \"Vietnam\":\"vn\",\n",
    "              }\n",
    "COUNTRIES.update(M_COUNTRIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = infection_data[:,-14:]\n",
    "test_data = np.expand_dims(test_data,axis=2)\n",
    "test_data = torch.Tensor(test_data).to(device)\n",
    "test_output = module(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accending = []\n",
    "decending = []\n",
    "print(\"missing : \")\n",
    "for i in range(len(country_names)):\n",
    "    try:\n",
    "        if test_output[i][0] > evaluate_thres:\n",
    "            accending.append(COUNTRIES[country_names.iloc[i]])\n",
    "        else:\n",
    "            decending.append(COUNTRIES[country_names.iloc[i]])\n",
    "    except:\n",
    "        print(\"    %s\"%country_names.iloc[i])\n",
    "\n",
    "worldmap_chart = pygal.maps.world.World()\n",
    "worldmap_chart.title = 'infections prediction'\n",
    "worldmap_chart.add('accending', accending)\n",
    "worldmap_chart.add('deccending', decending)\n",
    "worldmap_chart.add('no data', COUNTRIES.values())\n",
    "\n",
    "worldmap_chart.render_to_png(visual_folder+'/map.png')\n",
    "# Image(filename=visual_folder+'/map.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
