{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "visual_folder = 'visual'\n",
    "try:\n",
    "    os.mkdir(visual_folder)\n",
    "except:\n",
    "    print(visual_folder+' folder already exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(label):\n",
    "    label = label.astype('int32')\n",
    "    y = np.eye(10)[label.reshape(-1)]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(\"train.npz\")\n",
    "test_data = np.load(\"test.npz\")\n",
    "\n",
    "\n",
    "train_image = train_data['image']\n",
    "train_label = to_one_hot(train_data['label'])\n",
    "train_input = train_image.reshape(train_image.shape[0],-1)\n",
    "# plt.imshow(train_image[0])\n",
    "# print('label : ',train_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_data['image']\n",
    "test_label = to_one_hot(test_data['label'])\n",
    "test_input = test_image.reshape(test_image.shape[0],-1)\n",
    "# plt.imshow(test_image[1])\n",
    "# print('label : ',test_label[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "\n",
    "def reluDerivative(z):\n",
    "    z[z<=0] = 0\n",
    "    z[z>0] = 1\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     cross entropy\n",
    "def loss(y, y_hat):\n",
    "    y = y.T\n",
    "    l_sum = np.sum(np.multiply(y, np.log(y_hat)))\n",
    "    batch_num = y.shape[1]\n",
    "    l = -(1./batch_num) * l_sum\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, theta):\n",
    "    x = x.T\n",
    "    tmp = {}\n",
    "    \n",
    "    tmp[\"z1\"] = np.matmul(theta['w1'],x) + theta['b1']\n",
    "    tmp['a1'] = sigmoid(tmp['z1'])\n",
    "    \n",
    "    tmp['z2'] = np.matmul(theta['w2'],tmp['a1']) + theta['b2']\n",
    "    tmp['a2'] = tmp['z2']\n",
    "    \n",
    "    tmp['z3'] = np.matmul(theta['w3'],tmp['a2']) + theta['b3']\n",
    "    #soft max\n",
    "    tmp['a3'] = np.exp(tmp['z3']) / np.sum(np.exp(tmp['z3']),axis=0)\n",
    "    \n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x,y,theta,tmp):\n",
    "    x = x.T\n",
    "    y = y.T\n",
    "    b_size = x.shape[0]\n",
    "    \n",
    "    dz3 = tmp[\"a3\"] - y\n",
    "    dw3 = (1./b_size)*np.matmul(dz3, tmp['a2'].T)\n",
    "    db3 = (1./b_size)*np.sum(dz3,axis=1,keepdims=True)\n",
    "    \n",
    "    da2 = np.matmul(theta['w3'].T,dz3)\n",
    "    dz2 = da2\n",
    "    dw2 = (1./b_size)*np.matmul(dz2, tmp['a1'].T)\n",
    "    db2 = (1./b_size)*np.sum(dz2,axis=1,keepdims=True)\n",
    "    \n",
    "    da1 = np.matmul(theta['w2'].T,dz2)\n",
    "    dz1 = da1 * sigmoid(tmp['z1']) * (1 - sigmoid(tmp['z1']))\n",
    "    dw1 = (1./b_size)*np.matmul(dz1, x.T)\n",
    "    db1 = (1./b_size)*np.sum(dz1,axis=1,keepdims=True)\n",
    "\n",
    "    gradients = {'dw1':dw1, 'db1':db1, 'dw2':dw2, 'db2':db2, 'dw3':dw3, 'db3':db3}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(y, y_hat):\n",
    "    y_hat = y_hat.T\n",
    "    r = 0\n",
    "    y_ans = np.argmax(y,axis=1)\n",
    "    y_hat_ans = np.argmax(y_hat,axis=1)\n",
    "    w = np.count_nonzero(y_ans-y_hat_ans)\n",
    "    return w/float(y.shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.4\n",
    "epochs = 1000\n",
    "\n",
    "input_shape = train_input.shape[1]\n",
    "output_shape = 10\n",
    "n_hidden1 = 64\n",
    "n_hidden2 = 2\n",
    "batch_size = 60\n",
    "\n",
    "# use random init state\n",
    "theta = {\"w1\": np.random.randn(n_hidden1, input_shape) * np.sqrt(1. / input_shape),\n",
    "          \"b1\": np.zeros((n_hidden1, 1)) * np.sqrt(1. / input_shape),\n",
    "          \"w2\": np.random.randn(n_hidden2, n_hidden1) * np.sqrt(1. / n_hidden1),\n",
    "          \"b2\": np.zeros((n_hidden2, 1)) * np.sqrt(1. / n_hidden2),\n",
    "          \"w3\": np.random.randn(output_shape, n_hidden2) * np.sqrt(1. / output_shape),\n",
    "          \"b3\": np.zeros((output_shape, 1))}\n",
    "\n",
    "# use zero init state\n",
    "# theta = {\"w1\": np.zeros((n_hidden1, input_shape)),\n",
    "#           \"b1\": np.zeros((n_hidden1, 1)),\n",
    "#           \"w2\": np.zeros((n_hidden2,n_hidden1)),\n",
    "#           \"b2\": np.zeros((n_hidden2,1)),\n",
    "#           \"w3\": np.zeros((output_shape, n_hidden2)),\n",
    "#           \"b3\": np.zeros((output_shape, 1))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    permutation = np.random.permutation(train_input.shape[0])\n",
    "    train_x = train_input[permutation,: ].reshape(-1,batch_size,train_input.shape[1])\n",
    "    train_y = train_label[permutation,: ].reshape(-1,batch_size,train_label.shape[1])\n",
    "    \n",
    "    for f,(x,y) in enumerate(zip(train_x,train_y)):\n",
    "        \n",
    "        tmp = forward(x, theta)\n",
    "        gradients = backward(x, y, theta, tmp)\n",
    "\n",
    "        # apply gradient\n",
    "        theta[\"w1\"] = theta[\"w1\"] - learning_rate * gradients['dw1']\n",
    "        theta[\"b1\"] = theta[\"b1\"] - learning_rate * gradients['db1']\n",
    "        theta[\"w2\"] = theta[\"w2\"] - learning_rate * gradients['dw2']\n",
    "        theta[\"b2\"] = theta[\"b2\"] - learning_rate * gradients['db2']\n",
    "        theta[\"w3\"] = theta[\"w3\"] - learning_rate * gradients['dw3']\n",
    "        theta[\"b3\"] = theta[\"b3\"] - learning_rate * gradients['db3']\n",
    "\n",
    "    # training loss\n",
    "    tmp = forward(train_input, theta)\n",
    "    train_loss = loss(train_label, tmp[\"a3\"])\n",
    "    train_feature = tmp['a2']\n",
    "    train_error = error_rate(train_label, tmp[\"a3\"])\n",
    "\n",
    "    # test loss\n",
    "    tmp = forward(test_input, theta)\n",
    "    test_error = error_rate(test_label, tmp[\"a3\"])\n",
    "    test_feature = tmp['a2']\n",
    "    \n",
    "\n",
    "    print(\"Epoch {:3}: training loss = {:.4f}, test error = {:.4f}, train error = {:.4f} \".format(i + 1, train_loss, test_error, train_error))\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)\n",
    "    \n",
    "    if i%100==0:\n",
    "        data = pd.DataFrame({\"x\": train_feature[0], \"y\": train_feature[1], \"label\": train_data['label'].astype('int32')})\n",
    "        groups = data.groupby(\"label\")\n",
    "        for name, group in groups:\n",
    "            plt.plot(group[\"x\"], group[\"y\"], marker=\"o\", linestyle=\"\", label=name)\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(1.1, 1))\n",
    "        plt.title('latent feature at epoch:%d'%i)\n",
    "        plt.savefig(visual_folder+'/latent_feature%d.png'%i, bbox_inches = \"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.ylabel('average cross entropy')\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Training loss')\n",
    "plt.savefig(visual_folder+'/train_losses.png', bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(train_errors)\n",
    "plt.ylabel('error rate')\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Train error rate')    \n",
    "plt.savefig(visual_folder+'/train_errors.png', bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test_errors)\n",
    "plt.ylabel('error rate')\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Test error rate')    \n",
    "plt.savefig(visual_folder+'/test_errors.png', bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = forward(test_input, theta)\n",
    "y_pred = np.argmax(tmp['a3'],axis=0)\n",
    "y_true = test_data['label']\n",
    "cf_mat = confusion_matrix(y_pred,y_true)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(cf_mat,figsize=(16,16),colorbar=True)\n",
    "plt.savefig(visual_folder+'/confusion_matrix.png', bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
